<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>math/stats on</title><link>https://wiki.yigit.run/tags/math/stats/</link><description>Recent content in math/stats on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://wiki.yigit.run/tags/math/stats/index.xml" rel="self" type="application/rss+xml"/><item><title>Gaussian Distribution For Higher Dimensions</title><link>https://wiki.yigit.run/notes/Gaussian-Distribution-For-Higher-Dimensions/</link><pubDate>Sun, 16 Oct 2022 02:31:33 +0200</pubDate><guid>https://wiki.yigit.run/notes/Gaussian-Distribution-For-Higher-Dimensions/</guid><description>The [[notes/Gaussian Distribution]] can be extended to work in datasets with more than one dimension.</description></item><item><title>Gaussian Distribution</title><link>https://wiki.yigit.run/notes/Gaussian-Distribution/</link><pubDate>Sun, 16 Oct 2022 02:26:16 +0200</pubDate><guid>https://wiki.yigit.run/notes/Gaussian-Distribution/</guid><description>The gaussian distribution, also called the normal distribution occurs in many places in life. It is defined like so:
$$ p(x | \mu, \sigma) = \frac{1}{\sqrt{2\pi \sigma^2}}exp(-\frac{(x-\mu)^2}{2\sigma^2}) $$</description></item><item><title>Conditional And Total Risk</title><link>https://wiki.yigit.run/notes/Conditional-And-Total-Risk/</link><pubDate>Sun, 25 Sep 2022 05:09:37 +0200</pubDate><guid>https://wiki.yigit.run/notes/Conditional-And-Total-Risk/</guid><description>The conditional risk of assigning an object $x$ to the class $\omega_i$ is ( given the [[notes/Misclassification Cost|missclassification costs]]): $$ l^i(x) = \sum_{j=1}^C \lambda_{j,i}p(\omega_j|x) $$ This means the average risk(expectation) over a region $\Omega_i$ is: $$ $$ $$ \begin{align*} r^i &amp;amp;= \int_{\Omega_i} l^i(x)p(x)dx \ &amp;amp;= \int_{\Omega_i} \sum_{j=1}^C \lambda_{j,i}p(\omega_j|x)p(x)dx \end{align*} $$</description></item><item><title>Errors in a more general sense</title><link>https://wiki.yigit.run/notes/Errors-in-a-more-general-sense/</link><pubDate>Sun, 25 Sep 2022 03:55:16 +0200</pubDate><guid>https://wiki.yigit.run/notes/Errors-in-a-more-general-sense/</guid><description>For a two-type [[notes/Classification|classification]] problem: There are two different types of errors: $\varepsilon_1$ and $\varepsilon_2$. You can calculate them like so:</description></item><item><title>Types of Errors</title><link>https://wiki.yigit.run/notes/Types-of-Errors/</link><pubDate>Sun, 25 Sep 2022 03:30:12 +0200</pubDate><guid>https://wiki.yigit.run/notes/Types-of-Errors/</guid><description>In classification, an error is often represented by the symbol $\epsilon$. A misclassification can be one of two types:
False Positive (Type I): A false positive is misclassfying a given data point to belong to a class while it actually is not.</description></item></channel></rss>