<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Split this note into multiple notes  Anatomy of a compiler  Compilation Diagram
Front-End analysis   Lexical analysis: Lexical analysis is the process of taking the source code as a stream of characters and splitting it into tokens (Tokens are sequences of characters that have a collective meaning."><title>Anatomy of a compiler</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://wiki.yigit.run//icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><link href=https://wiki.yigit.run/styles.17c207d215c8f39002e5e4ff917cfb6e.min.css rel=stylesheet><link href=https://wiki.yigit.run/lib/fontawesome.min.6386fb409d4a2abc96eee7be8f6d4cc4.css rel=stylesheet><script src=https://wiki.yigit.run/js/gnuplot_api.8e1c31098e0ba119f7824a661b56d4a4.min.js></script>
<script>const gnuplot_link="/js/gnuplot.44eb85f3f3fb2223f46a016f467bd5b4.js"</script><script src=https://wiki.yigit.run/js/gnuplot_render.f03d1b9dc0e81e8e9b17ea995631e7ce.min.js></script>
<script src=https://wiki.yigit.run/js/darkmode.60008d21c68ae1873118e110b3a2aeda.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script src=https://wiki.yigit.run/js/popover.688c5dcb89a57776d7f1cbeaf6f7c44b.min.js></script>
<script>const BASE_URL="https://wiki.yigit.run/",fetchData=Promise.all([fetch("https://wiki.yigit.run/indices/linkIndex.d360c5558300c7e1545ddc021a994922.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://wiki.yigit.run/indices/contentIndex.d33b11c3c67458cbd6b1c72df99da6a2.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const n=new URL("https://wiki.yigit.run/"),s=n.pathname,o=window.location.pathname,i=s==o,e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=i&&!0;drawGraph("https://wiki.yigit.run",t,[{"/moc":"#4388cc"}],t?{centerForce:100,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.3,linkDistance:.1,opacityScale:3,repelForce:.1,scale:.7}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2}),initPopover("https://wiki.yigit.run",!0,!0)},init=(e=document)=>{renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/wiki.yigit.run\/js\/router.b65d0bc2e726311cb6574ae9a7ad27fb.min.js"
    attachSPARouting(init, render)
  </script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://wiki.yigit.run/js/search.cf33b507388f3dfd5513a2afcda7af41.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://wiki.yigit.run/>Neocortex </a></h1><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Anatomy of a compiler</h1><p class=meta>Last updated November 16, 2021</p><ul class=tags><li><a href=https://wiki.yigit.run/tags/cs/compiler/>Cs compiler</a></li><li><a href=https://wiki.yigit.run/tags/cs/low-level/>Cs low level</a></li></ul><ul><li><input disabled type=checkbox> Split this note into multiple notes</li></ul><a href=#anatomy-of-a-compiler><h1 id=anatomy-of-a-compiler><span class=hanchor arialabel=Anchor># </span>Anatomy of a compiler</h1></a><p><a rel=noopener class="internal-link broken" data-src=./static/Anatomy_of_a_compiler/2021-06-06T13:21:22.png>Compilation Diagram</a></p><a href=#front-end-analysis><h2 id=front-end-analysis><span class=hanchor arialabel=Anchor># </span>Front-End analysis</h2></a><ol><li><p><strong>Lexical analysis:</strong> Lexical analysis is the process of taking the source code as a stream of characters and splitting it into <code>tokens</code> (Tokens are sequences of characters that have a collective meaning.).</p></li><li><p><strong>Syntax analysis & Parsing:</strong> Syntax analysis is the process of parsing a sequence of tokens generated in lexical analysis and outputting a <code>parse-tree</code> or a <code>derivation</code>.</p></li><li><p><strong>Semantic Analysis:</strong> In semantic analysis we check the code for non-syntactic but semantic errors. These errors include improper arguments, access violations and undeclared variables. An example of a semantic error is:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>foo</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>foo</span> <span class=o>+</span> <span class=mi>2</span> <span class=c1># You can&#39;t add an int to a list</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p><strong>Intermediate Code Generation:</strong> In this step we create the <code>intermediate representation</code> of the source code. Intermediate representation should be easy to generate and translate to the target program. A very common form is the <code>three-address code(TAC)</code> which is a sequence of simple instructions with at most three operands.</p></li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>      real code            TAC
</span></span><span class=line><span class=cl>      -------------------- ---------------
</span></span><span class=line><span class=cl>      a = ( c + b ) \* 2   ~t1~ = c + b
</span></span><span class=line><span class=cl>                           a = ~t1~ \* 2
</span></span></code></pre></td></tr></table></div></div><a href=#back-end-analysis-synthesis><h2 id=back-end-analysis-synthesis><span class=hanchor arialabel=Anchor># </span>Back-End analysis (Synthesis)</h2></a><ol><li><strong>Intermediate Code Optimisation:</strong> This stage accepts the <code>intermediate representation</code> generated in <strong>Intermediate Code Generation</strong> and applies several optimisation techniques to it including but not limited to:<ul><li>suppressing code generation of unreachable code segments,</li><li>ridding of unused variables,</li><li>eliminating multiplication by 1 and addition by 0,</li><li>loop optimisation (e.g., remove statements that are not modified in the loop),</li><li>common sub-expression elimination,</li></ul></li><li><strong>Object Code Generation:</strong> In this step, the target program gets generated. This step usually outputs either machine code or assembly.</li><li><strong>Object Code Optimisation:</strong> This is a non-mandatory step that processes the machine code generated and applies hardware-specific optimisations such as special instructions, pipelining and branch prediction).</li></ol><a href=#lexical-analysis><h1 id=lexical-analysis><span class=hanchor arialabel=Anchor># </span>Lexical Analysis</h1></a><p><a rel=noopener class="internal-link broken" data-src=./static/Lexical_Analysis/2021-06-06T13:38:04.png>Lexical Analysis Diagram</a></p><p>A lexical analyser takes a stream of characters and generates tokens as its output. It can recognise particular instances of tokens which are called <code>lexemes</code>. A lexeme is the actual sequence forming a token. The scanner&rsquo;s task is to determine the tokens from an input stream but it has no idea where the tokens belong to. Therefore it can only detect errors caused by invalid tokens, it can&rsquo;t detect out of place tokens, mismatched parentheses etc. The lexical analyser is a convenient tool to strip out comments and unnecessary white spaces</p><a href=#how-rules-are-implemented><h2 id=how-rules-are-implemented><span class=hanchor arialabel=Anchor># </span>How rules are implemented</h2></a><p>When scanning a stream of characters, an analyser might encounter situations where multiple rules match the same string or some rules might match a substring of another rule that matches a longer string. In order to prevent undefined behaviour in those cases, the scanner uses these two principles:</p><ul><li>If the same string is matched by two or more rules, the rule that was defined first is used.</li><li>If two strings are matched by the same rule, the longer string is considered to be a lexeme and turned into a token.</li></ul><a href=#scanner-implementation-with-regular-expressions-and-finite-automata><h2 id=scanner-implementation-with-regular-expressions-and-finite-automata><span class=hanchor arialabel=Anchor># </span>Scanner Implementation with Regular Expressions and Finite Automata</h2></a><a href=#important-terminology><h3 id=important-terminology><span class=hanchor arialabel=Anchor># </span>Important terminology</h3></a><ul><li><code>symbol</code> an abstract entity that we shall not define formally (such as "point" in geometry). Letters, digits and punctuation are examples of symbols.</li><li><code>alphabet</code> a finite set of symbols out of which we build larger structures, typically denoted by 危.</li><li><code>formal language 危*</code> the set of all possible strings that can be generated from a given alphabet</li></ul><a href=#from-regex-to-automata><h3 id=from-regex-to-automata><span class=hanchor arialabel=Anchor># </span>From RegEx to Automata</h3></a><p>A finite automata can be used to implement scanners in the following manner:</p><ul><li>The scanner reads the source program one character at a time, changing its state accordingly.</li><li>The automaton starts from an initial state and makes moves according to the the next character in the stream, changing its state along the way.</li><li>When the automaton ends up in one of the final states, it makes a move associated with that state, after that, the procedure restarts from the point in the stream that we left off.</li><li>If an unexpected symbol(a symbol which does not have an action associated with it in our current state) occurs, an error condition is formed.</li></ul><ol><li><p>Nondeterministic Finite Automata</p><p>What sets an NFA different from a Deterministic Finite Automata(DFA) is that a state can have 蔚 moves(moves that don't shift the input stream) and multiple moves from the same state that are associated with the same character. These features allow us to more easily generate NFAs from regular expressions.</p><p>An NFA that accepts the RegEx <code>(0|1)*(000|111)(0|1)*</code>
<a rel=noopener class="internal-link broken" data-src=./static/Lexical_Analysis/2021-06-06T19:46:57_RegToNFA.png>RegToNFA</a></p><p>When generating an NFA from a regular expression, one can follow the following rules:</p><ul><li><p><code>Rule 1</code> An NFA that accepts any symbol from the alphabet</p><p><a rel=noopener class="internal-link broken" data-src=./static/Lexical_Analysis/2021-06-06T19:47:14_NFAR1.png>NFAR1</a></p></li><li><p><code>Rule 2</code> An NFA that accepts only 系</p><p><a rel=noopener class="internal-link broken" data-src=./static/Lexical_Analysis/2021-06-06T19:49:15_NFAR2.png>NFAR2</a></p></li><li><p><code>Rule 3</code> An 系 NFA that accepts <code>r1|r2</code></p><p><a rel=noopener class="internal-link broken" data-src=./static/Lexical_Analysis/2021-06-06T19:51:28_NFAR3.png>NFAR3</a></p></li><li><p><code>Rule 4</code> An 系 NFA that accepts <code>r1r2</code></p><p><a rel=noopener class="internal-link broken" data-src=./static/Lexical_Analysis/2021-06-06T19:53:04_NFAR4.png>NFAR4</a></p></li><li><p><code>Rule 5</code> An 系 NFA that accepts <code>r1*</code></p><p><a rel=noopener class="internal-link broken" data-src=./static/Lexical_Analysis/2021-06-06T19:53:50_NFAR5.png>NFAR5</a></p></li></ul></li><li><p>Converting from NFA to Deterministic Finite Automata</p><p>In the process of conversion from NFA to DFA we use a technique called <code>subset construction</code>. Each state in the resulting DFA is made up of a set of states from the original NFA and it has the same start state and the same alphabets. This means that given a state from the original NFA, an input symbol <code>x</code> takes us from our current state to all the possible states we can reach using the x move and 系 moves. The combined set of all those states form a new state in our DFA. Therefore, each state in our DFA is a subset of S(the set of states in our NFA) so it can have at most $2^n$ states, n being the size of the set S.</p></li></ol><a href=#flex-overview><h1 id=flex-overview><span class=hanchor arialabel=Anchor># </span>flex Overview</h1></a><p><strong>flex</strong> allows you to specify the scanner you want using patterns to match and actions to apply. It then uses the language you specified to generate and NFA, then converts it into an equivalent DFA and generates C code that implements that automaton. You can learn more about flex
<a href=http://flex.sourceforge.net/manual/ rel=noopener>here</a> or by running <code>info flex</code>.</p><a href=#a-flex-input-file><h2 id=a-flex-input-file><span class=hanchor arialabel=Anchor># </span>A flex Input File</h2></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>%{
</span></span><span class=line><span class=cl>Declarations
</span></span><span class=line><span class=cl>%}
</span></span><span class=line><span class=cl>Definitions
</span></span><span class=line><span class=cl>%%
</span></span><span class=line><span class=cl>Rules
</span></span><span class=line><span class=cl>%%
</span></span><span class=line><span class=cl>User subroutines
</span></span></code></pre></td></tr></table></div></div><p>The optional fields <strong>Declarations</strong> and <strong>User subroutines</strong> sections are copied directly to the generated C. In the <strong>Definitions</strong> field you specify options for the scanner and setup definitions to give names to regular expressions. The only required field, <strong>Rules</strong> allows you to specify patterns that identify your tokens and the actions performed upon recognising. Rules in flex are simply RegEx rules.</p><a href=#flex-global-variables><h2 id=flex-global-variables><span class=hanchor arialabel=Anchor># </span>flex Global variables</h2></a><p>The <strong>yylex</strong> function is a function that takes no argument and returns an integer, it is the token-grabbing function. Since it returns nothing, it sets global variables that be read by the caller. Here are the global variables it uses:</p><ul><li><code>yytext</code> is a null-terminated string containing the text of the lexeme just recognised.</li><li><code>yyleng</code> is an integer holding the length of the lexeme stored in <code>yytext</code></li><li><code>yylval</code> is the global variable used to store attributes about the token, it is of type YYSTYPE.</li><li><code>yylloc</code> is the global variable used to store the location of the lexeme</li></ul><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script>
<script>mermaid.initialize({startOnLoad:!0,theme:"dark"}),GnuplotRenderer.renderPage()</script></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282;--g-node-tag:#e8c410}</style><script src=https://wiki.yigit.run/js/graph.2bdcb20a9aaee1234c2a6e0372a1a485.js></script></div></div><div id=contact_buttons><footer><p>Made by Yigit Colakoglu using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, 漏 2022</p><ul><li><a href=/>Home</a></li><li><a href=https://twitter.com/theFr1nge>Twitter</a></li><li><a href=https://github.com/theFr1nge>Github</a></li></ul></footer></div></div></body></html>